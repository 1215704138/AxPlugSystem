# AxPlugSystem 事件总线 (Event Bus) 需求规格说明书

## 1. 引言

在具有高扩展性的 `AxPlugSystem` 插件化架构中，插件之间以及核心框架与插件之间需要一种高度解耦的通信机制。引入事件总线（Event Bus）能够彻底消除组件间的直接函数调用依赖，实现真正的“开闭原则”。

本文档参考了工业级插件框架 `z3y` 的卓越实现，为 `AxPlugSystem` 设计了下一代事件总线的需求基线，并提取了其可吸收的设计优势。

---

## 2. 核心需求描述

### 2.1 基于数据驱动的类型安全事件抽象
- **需求**: 所有的事件应当被抽象为具体的结构体/类（继承自基础 `Event` 类型）。事件的分发不仅要传递一个“动作名或ID”，更要能携带强类型的数据载荷（Payload）。
- **目的**: 避免像传统基于字符串字典（如 JSON）那样的序列化/反序列化开销，直接在同一进程内存中传递 C++ 数据结构首地址。

### 2.2 灵活的通信模式（全局广播与定向监听）
- **需求**:
  1. **全局广播 (Global Broadcast)**: 发布者发出事件，所有订阅该类型事件的组件都会收到通知。
  2. **定向/特定发送者监听 (Sender-Specific)**: 订阅者不仅限定“事件类型”，还限定“事件发布者”。只有特定的模块（如特定的某个 Camera Service）发出该事件时，订阅者才做出响应。

### 2.3 RAII 风格的安全连接管理
- **需求**: 每次订阅操作都应返回一个底层的 `Connection` 或 `Token` 对象。
- **目的**: 当订阅者的生命周期结束时（如对应的类实例被析构），通过该对象的析构函数能够自动在总线中解绑，避免产生悬垂指针 (Dangling Pointer) 导致崩溃。

### 2.4 同步与异步触发机制
- **需求**: 能够提供同步回调 (`DirectCall`) 和异步排队 (`Queued`) 两种派发选项。
- **目的**:
  - 同步调用：适用于对延迟极其敏感，且必须立刻获取返回值（或在调用栈中处理引用参数）的场景。
  - 异步排队：适用于将耗时任务或 UI 更新操作推迟到独立的工作线程（或主线程的 EventLoop 中）去执行，避免阻塞当前的发布者业务逻辑。

---

## 3. 可吸收的 Z3Y 核心优势（架构亮点）

在分析 `z3y_plugin_framework` 后，建议 `AxPlugSystem` 的事件总线在实现时全盘吸收以下 **五大底层工业级优势**：

### 优势一：彻底解决死锁的 COW（写时复制）派发机制
在事件派发（Fire）的遍历过程中，经常会发生订阅者在回调函数内部请求“取消订阅自身”或“订阅其他新事件”的情况。普通框架使用`std::mutex`就会导致死锁，使用`std::recursive_mutex`也会由于迭代器失效而崩溃。
- **Z3Y 的解法**: 对订阅列表采用 **COW (Copy-On-Write)** 策略。发布（读取）时完全无锁（或只锁极短时间拿到 shared_ptr），任何修改（新增/删除订阅）都会复制出一个全新的订阅列表进行修改并原子替换。
- **吸收建议**: `AxPlugSystem` 的派发热路径 (Hot path) 必须采用类似 COW 的无锁/免锁设计，保障任何极端场景下绝对不会因回调嵌套产生死锁。

### 优势二：基于 WeakPtr 的内存安全“懒惰垃圾回收 (Lazy GC)”
如果采用严格的实时解绑，每次退订都需要写锁，极大伤害并发性能。
- **Z3Y 的解法**: 业务方的订阅句柄 `Connection` 被销毁时，仅仅是把内部的 `atomic<bool>` 标志位置为失效（或者弱引用 `expired`）。`FireGlobal` 在派发事件时，如果“顺便”遇到了失效票据，不仅跳过它，并在结束后在后台调度一次异步的 GC（垃圾回收）任务来清理。
- **吸收建议**: 将注销逻辑极度轻量化为单向标记位，彻底避免跨模块的析构竞态条件。真正的清理动作延迟合并到后台线程执行。

### 优势三：编译期的 TypeId 哈希碰撞杜绝
- **Z3Y 的解法**: 定义了宏（如 `Z3Y_DEFINE_EVENT`），并在编译期使用 `constexpr` 的字符串哈希函数（如 FNV-1a）将长字符串 UUID 直接换算为一个 64 位的整数作为事件的唯一标识符（`EventId`）。
- **吸收建议**: 放弃运行时使用 `std::string` 或 RTTI (`typeid`) 查找事件分发树，统一使用 64 位整型（C++17 string_view/constexpr hash）作为 key，实现 $O(1)$ 的无痛寻址。

### 优势四：MPSC 架构的异步事件引擎
- **Z3Y 的解法**: 内部实现了一个带条件变量和队列的专用 `EventLoop` 工作线程。当触发 `ConnectionType::kQueued` 的事件时，仅向队列丢入一个轻量级的 `lambda` 任务（携带对 `event_payload` 的 shared_ptr 共享），主调用方顺延无阻塞。
- **吸收建议**: 为 `AxPlugSystem` 的事件总线单独分配一条线程（或绑定到既有框架的 Worker 线程池中），赋予其处理 IO、日志落盘等不重要事件的旁路能力。

### 优势五：细粒度的 Trace 埋点 (Performance Hooks)
- **Z3Y 的解法**: 在 `FireGlobal`, `QueuePush`, `DirectCall`, `AsyncExecStart` 等多处核心逻辑前后，包裹了性能追踪探针。
- **吸收建议**: 考虑到 `AxPlugSystem` 可能需要进行深度 Profiling，事件总线内部必须保留这些执行时长探针的介入点，以便在查组件全链路延时（如音视频帧排队）时，拥有第一手可分析的性能回溯数据。

---

## 4. 各阶段实施建议路线图 (Roadmap)

1. **Phase 1（基础抽象与 COW 模型）**: 在 `AxPlugSystem` 核心定义最轻量的 `IEventBus` 纯虚接口与 `Event` 基类。实现基于 `std::shared_ptr<SubList>` 的 Copy-On-Write 同步派发器。
2. **Phase 2（内存安全与 GC）**: 引入 `Connection` 句柄，支持通过 `weak_ptr` 解析存活状态，配合“标记+扫描”的弱感知垃圾回收策略。
3. **Phase 3（异步线程与探针）**: 添加 `EventLoop` 支持异步投递，并对接框架现有的 Logger/Profiler，开启核心耗时的溯源统计。
